---
title: "DATS 6101 Project 1"
author: "Tyler Wallett, Anushka Vuppala and David Li"
# date: "today"
date: "`r Sys.Date()`"
output:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
    
---
```{r init, include=F}
library(tidyverse)
library(ezids)
```
<span style="color: Blue;"> Our research topic aims to perform explorartory data analysis on the Nearest Earth Objects (NEO) dataset recorded by NASA. This particular dataset includes thousands of labeled observations, over the last 22 years, across multiple attributes that each aim to describe a specific object. Borrowing from the humor of the recent film *Don’t Look Up* by Adam Mckay and NASA’s success in the Double Asteroid Redirection Test (DART) mission, we thought that further describing and exploring this dataset would be opportune.</span> 

```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# use scipen=999 to prevent scientific notation at all times
```


# Let's explore the dataset
```{r import_data, results='markup'}
neo <- data.frame(read.csv("neo.csv", header = TRUE))
```
Displaying the structure of the data:
```{r, results='markup'}
print(str(neo))
```
Displaying the first 6 rows of the dataset:
```{r, results='markup'}
print(head(neo))
```
The number of NA values in the dataset => `r sum(is.na(neo))`


Now, we split the dataset into 2 dataframes - one for hazardous and other for non-hazardous. This is to ease out the tests performed.

```{r split dataset, results='markup'}
hazardous = neo %>% filter(hazardous=="True")
non_hazardous = neo %>% filter(hazardous=="False")
```
The dimensions of hazardous asteroids dataframe: `r dim(hazardous)`

The dimensions of non_hazardous asteroids dataframe: `r dim(non_hazardous)`

# Performing measures of central tendency using Summary

Summary of all asteroids is as follows:
```{r summary, results='markup'}
summary(neo)
```


# Distinct Values
Now, there are multiple asteroids with the same "id" and "name" in the dataset. We shall remove these in order for the dataset to follow the rules of a relational dataset. 
We use the group_by function provided in R to do so and we take the mean of those asteroids with the same id and name so we don't have any risk of losing the data.
```{r distinct_hazardous_groupby, results='markup'}
hazardous_grouped = hazardous %>% group_by(name) %>% summarise(absolute_magnitude = mean(absolute_magnitude), relative_velocity = mean(relative_velocity), miss_distance = mean(miss_distance), hazardous = min(hazardous))
```
The dimension of the hazardous dataframe after using only distinct asteroid ID's => `r dim(hazardous_grouped)`



```{r distinct_non_hazardous_groupby, results='markup'}
non_hazardous_grouped = non_hazardous %>% group_by(name) %>% summarise(absolute_magnitude = mean(absolute_magnitude), relative_velocity = mean(relative_velocity), miss_distance = mean(miss_distance), hazardous = min(hazardous))
```
The dimension of the non_hazardous dataframe after using only distinct asteroid ID's => `r dim(non_hazardous_grouped)`


# Relative Velocity

```{r, results='markup'}
library(tidyverse)
neo <- read.csv("neo.csv")
hazardous = neo %>% filter(hazardous=="True")
safe = neo %>% filter(hazardous=="False")
xkablesummary(hazardous[c("relative_velocity")])
xkablesummary(safe[c("relative_velocity")])
ttest2sample_neo = t.test(hazardous$relative_velocity,safe$relative_velocity)
ttest2sample_neo

ttestsafe95 = t.test(x=safe$relative_velocity, conf.level = .95)
ttestsafe99 = t.test(x=safe$relative_velocity, conf.level = .99)
ttestsafe95$conf.int
ttestsafe99$conf.int

ttesthaz95 = t.test(x=hazardous$relative_velocity, conf.level = .95)
ttesthaz99 = t.test(x=hazardous$relative_velocity, conf.level = .99)
ttesthaz95$conf.int
ttesthaz99$conf.int

anovavelocity = aov(formula = relative_velocity ~ hazardous, data = neo)
xkabledply(anovavelocity)
```

```{r, results='markup'}
ggplot(data=hazardous, aes(relative_velocity)) + geom_histogram(col='red',fill="blue")+labs(x= "Velocity (km/s)", y="Frequency") + labs(title="Frequency Distribution of Hazardous Relative Velocities")

ggplot(data=safe, aes(relative_velocity)) + geom_histogram(col='red',fill="blue")+labs(x= "Velocity (km/s)", y="Frequency") + labs(title="Frequency Distribution of Safe Relative Velocities")
```

# Miss Distance

```{r, results='markup'}
#Tyler 
#1. Descriptive statistics
#2. [When Applicable] Measures of variance
#3. Graphical interpretations of the data
#4. [When Applicable] Normality tests
#5. [When Applicable] ANOVA analysis - T-test/Intervals
```

## 2. Descriptive statistics:

```{r, results='markup'}
#Tyler 
#2. Descriptive statistics:

neo_tyler = neo[c(2, 6, 10)] #getting the columns name, miss_distance and hazardous
neo_tyler$hazardous = factor(neo_tyler$hazardous)
#str(neo_tyler) #showing the data types

neo_tyler$miss_distance = neo_tyler$miss_distance/1.496e+8 #Expressing unit in au (astronomical units)

summary(neo_tyler$miss_distance) #summarizing only numeric variable in au

neo_tyler$miss_distance = (neo_tyler$miss_distance*1.496e+8)/1000000

library(dplyr)
grouped_data = neo %>% group_by(name) %>% summarise(miss_distance = mean(miss_distance), hazardous = min(hazardous))

neo_h_tyler = subset(grouped_data, grouped_data$hazardous == 'True') #Sub-setting the data into hazardous 
neo_nh_tyler = subset(grouped_data, grouped_data$hazardous == 'False') #Sub-setting the data into non-hazardous

neo_h_tyler$miss_distance = neo_h_tyler$miss_distance/1000000
neo_nh_tyler$miss_distance = neo_nh_tyler$miss_distance/1000000

summary(neo_h_tyler$miss_distance) #Summary of hazardous miss_distance
summary(neo_nh_tyler$miss_distance) #Summary of non-hazardous miss_distance
```

## 4. [When Applicable] Measures of variance / sd

```{r, results='markup'}
#Tyler 
#4. [When Applicable] Measures of variance / sd

#For neo_h_tyler as a whole:
sd(neo_h_tyler$miss_distance)

#For neo_nh_tyler as a whole:
sd(neo_nh_tyler$miss_distance)
```

## 3. Graphical interpretations of the data:

```{r, results='markup'}
#Tyler 
#3. Graphical interpretations of the data:

#Histograms:
library(ggplot2)

#For neo_h_tyler as a whole:
ggplot(neo_h_tyler, aes(miss_distance, ..count../sum(..count..)*100))+
  geom_histogram(col = 'black', fill ='red', bins = 20)+
  labs(title = 'Histogram of relative frequency for `Miss Distance` of hazardous (n=2173)')+
  xlab('Miss distance (millions of kilometers)')+
  ylab('Frequency %')

#For neo_nh_tyler as a whole:
ggplot(neo_nh_tyler, aes(miss_distance, ..count../sum(..count..)*100))+
  geom_histogram(col = 'black', fill ='green', bins = 20)+
  labs(title = 'Histogram of relative frequency for `Miss Distance` of not hazardous (n=25250)')+
  xlab('Miss distance (millions of kilometers)')+
  ylab('Frequency %')

#Boxplot:
#For neo_h_tyler and neo_nh_tyler as a whole:
ggplot(neo_tyler, aes(y=neo_tyler$miss_distance, x=neo_tyler$hazardous))+
  geom_boxplot(colour = c('green', 'red'))+
  labs(title = 'Boxplot of `Miss distance` vs hazardous variable')+
  xlab('Hazardous variable')+
  ylab('Miss distance (millions of kilometers)')+
  scale_x_discrete(labels = c('Not hazardous','hazardous'))

#QQ-plots:
#For neo_h_tyler as a whole:
qqnorm(neo_h_tyler$miss_distance, col='red', main = 'QQ Plot for `miss_distance` of hazardous (n=2173)')
qqline(neo_h_tyler$miss_distance)
#For neo_nh_tyler as a whole:
qqnorm(neo_nh_tyler$miss_distance, col='green', main = 'QQ Plot for `miss_distance` of not hazardous (n=25250)')
qqline(neo_nh_tyler$miss_distance)
#Clearly under-dispersed data, or platykurtic distribution, having negative excess kurtosis. 
```

## 6. [When Applicable] T-test/Intervals

```{r, results='markup'}
#Tyler 
#6. [When Applicable] T-test/Intervals

#For neo_h_tyler as a whole at 95%:
t.test(neo_h_tyler$miss_distance)

#For neo_nh_tyler as a whole at 95%:
t.test(neo_nh_tyler$miss_distance)

#Do not overlap, lets try again at a much higher level of confidence

#For neo_h_tyler as a whole at 99%:
t.test(neo_h_tyler$miss_distance, conf.level = 0.99)

#For neo_nh_tyler as a whole at 99%:
t.test(neo_nh_tyler$miss_distance, conf.level = 0.99)

#Still do not overlap, which raises the question of whether these means are different 
#So, lets run ANOVA...
```

## 6. [When Applicable] ANOVA
```{r, results='markup'}
#Tyler 
#6. [When Applicable] ANOVA

#H0: The mean for h and nh are the same 
#H1: The means are NOT the same

grouped_data$miss_distance = grouped_data$miss_distance/1000000

anova_tyler = aov(grouped_data$miss_distance ~ grouped_data$hazardous, neo_tyler)
summary(anova_tyler)

# Post-Hoc Follow-up
tukeyAoV <- TukeyHSD(anova_tyler)
tukeyAoV
```


# Absolute Magnitude 
Summary of absolute_magintude of hazardous asteroid: 
```{r, results='markup'}
summary(hazardous$absolute_magnitude)
```

Summary of absolute_magnitude of non-hazardous NEO: 
```{r, results='markup'}
summary(non_hazardous$absolute_magnitude)
```
 
## Let's find the mode

```{r finding_mode, results='markup'}
getmode <- function(v) {
   uniqv <- unique(v)
   uniqv[which.max(tabulate(match(v, uniqv)))]
}
```
Mode of absolute_magnitude in neo dataset => `r getmode(neo$absolute_magnitude)`

Mode of absolute_magnitude in hazardous dataset => `r getmode(hazardous$absolute_magnitude)`

Mode of absolute_magnitude in non-hazardous dataset => `r getmode(non_hazardous$absolute_magnitude)`


## Measures of Variance and Standard Deviation


Variation of absolute_magnitude of hazardous NEO => `r var(hazardous$absolute_magnitude)`

Variation of absolute_magnitude of non_hazardous NEO => `r var(non_hazardous$absolute_magnitude)`



Standard deviation of absolute_magnitude of hazardous NEO => `r sd(hazardous$absolute_magnitude)`

Standard deviation of absolute_magnitude of non_hazardous NEO => `r sd(non_hazardous$absolute_magnitude)`

## Graphical understanding using Plots

```{r graphical_representation}
ggplot(hazardous, aes(x=absolute_magnitude)) + geom_histogram(bins=70, color="black", fill="pink") + labs(x="Absolute Magnitude", y="Frequency Count", title = "Histogram of absolute_magnitude of hazardous asteroids")

ggplot(non_hazardous, aes(x=absolute_magnitude)) + geom_histogram(bins=70, color="black", fill="lightblue") + labs(x="Absolute Magnitude", y="Frequency Count", title = "Histogram of absolute_magnitude of non_hazardous asteroids")

ggplot(neo, aes(x=absolute_magnitude, y=hazardous)) + geom_point(col = "green") + labs(x="Absolute Magnitude", y="Hazardous", title = "Scatter plot for hazardous vs non-hazardous asteroids")

qqnorm(hazardous$absolute_magnitude, main="QQ Plot of the absolute magnitude of hazardous asteroids")

qqnorm(non_hazardous$absolute_magnitude, main="QQ Plot of the absolute magnitude of non-hazardous asteroids")
```

Note - We see that the absolute_magnitude for hazardous NEO lies mostly between 19 to 22. While that of the non-hazardous asteroids gnerally lies between 23 to 27. 

## Outliers
Knowing if the dataset has outliers is a good way to know if the dataset has any "bad data". And it is essential to know or keep track of the number of records that represent outliers. To keep track of the outliers in the dataset, we shall use outlierKD2 function:
```{r hazardous_outlier_removal, results='markup'}
hazardous_outlier_removed = outlierKD2(hazardous,absolute_magnitude, qqplt=TRUE, rm=TRUE)
```
The dimension of the hazardous dataframe after removing outliers: `r dim(hazardous_outlier_removed)`


```{r outlier_non_hazardous_removal, results='markup'}
non_hazardous_outlier_removed = outlierKD2(non_hazardous,absolute_magnitude, qqplt=TRUE, rm=TRUE)
```

The dimension of the non_hazardous dataframe after removing outliers: `r dim(non_hazardous_outlier_removed)`

## T-Tests
Now, with all outliers removed and distinct values extracted, we can perform t-tests.

T-Tests on hazardous dataframe:
```{r t-test-hazardous, results='markup'}
t.test(hazardous_grouped$absolute_magnitude)
```

T-Tests on non_hazardous dataframe:
```{r t-test-non-hazardous, results='markup'}
t.test(non_hazardous_grouped$absolute_magnitude)
```

## Contingency Table
Now, we shall validate the above by printing the Contingency table.
The contingency table of hazardous is below:
```{r frequency_cut_hazardous, results='markup'}
table(cut(hazardous_grouped$absolute_magnitude,seq(16,23,0.5)))
```

We see a higher frequency of values falling in the interval 21-22 for hazardous asteroids. However, as noticed in the plots drawn, the plot is left skewed. Hence, the average/mean shifted a bit towards the left. 


The contingency table of non_hazardous is below:
```{r frequency_cut_non_hazardous, results='markup'}
table(cut(non_hazardous_grouped$absolute_magnitude,seq(16,32,0.5)))
```

We see a higher frequency of values falling in the interval 24-25 for non_hazardous.

## Anova Test:
For anova test, we need 2 samples of equal size - one from hazardous and another from non-hazardous
```{r aov_test, results='markup'}
# creating a third column in both dataframes to account for categorical variable - hazardous
non_hazardous_grouped$hazardous=0
hazardous_grouped$hazardous=1
non_hazardous_sample = sample(1:nrow(non_hazardous_grouped), size=2105)
summary(aov(absolute_magnitude ~ hazardous, data=rbind(hazardous_grouped, non_hazardous_sample)))
```

Observation - the p-value is a small number (<0.001) which indicates that we can reject the null hypothesis and confirm that the mean for hazardous and non-hazardous NEOs is not the same. 
Note that the p-value is same from results obtained in anova test and t-test.


## Correlation with Diameter
A correlation plot is used to determine how close each variable is to the other. Knowing that absolute magnitude indicates the size of the NEO, we shall draw a correlation plot with est_diameter_min and est_diameter_max to see if it does hold significance or not?
```{r correlation_magnitude_diameter, results='markup'}
library(corrplot)
corrplot(cor(hazardous %>% select(absolute_magnitude, est_diameter_min, est_diameter_max), method = "pearson"), method="number", title="Pearson correlation of absolute magnitude with diameter variables", mar=c(1,1,1,1))
```

As noted in the above correlation plot, we see that the the min and max estimated diameter is closely related to the absolute magnitude. It is inversely related. This makes sense because absolute magnitude (brightness of a NEO) indicates the size of the asteroid in question. And hence, we can say that the bigger the size of the asteroid, lesser the absolute magnitude (brighter the star), and thus potentially more hazardous is the asteroid.



# Overall Correlation Plots:
After exploring each of these 3 variables, we shall now see their correlation with that of our target variable - hazardous. We shall draw both - Pearson and Spearman correlation plots. 

```{r, results='markup'}
hazardous$hazardous = as.integer(as.logical(hazardous$hazardous))
non_hazardous$hazardous = as.integer(as.logical(non_hazardous$hazardous))

corrplot(cor(rbind(hazardous, non_hazardous) %>% select(absolute_magnitude, miss_distance, relative_velocity, est_diameter_min, est_diameter_max, hazardous ), method= "pearson"), method="number", title = "Pearson Correlation", outline = TRUE, mar = c(1,1,1,1))

corrplot(cor(rbind(hazardous, non_hazardous) %>% select(absolute_magnitude, miss_distance, relative_velocity, est_diameter_min, est_diameter_max, hazardous ), method= "spearman"), method="number", title = "Spearman Correlation", outline = TRUE, mar = c(1,1,1,1))
```

Here, we see that hazardous variable has a higher correlation with asbsolute magnitude, and the diameter variables. This means that the size of the asteroid plays a very significant role in deciding if the asteroid is hazardous or not. 






