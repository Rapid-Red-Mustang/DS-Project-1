boxplot(neo1hsample$miss_distance, neo1nhsample$miss_distance)
#Given that there is just too much data, im going to create random samples -> everyone can replicate
set.seed(999)
neo1hsample = neo1h[ sample(nrow(neo1h), 100), ]
neo1nhsample = neo1nh[ sample(nrow(neo1nh), 100), ]
# mlbsample2 = mlb[ sample(nrow(mlb),20), ] from zt r file in class
#Same visualization stuff again on samples...
library(ggplot2)
hist(neo1hsample$miss_distance)
hist(neo1nhsample$miss_distance)
qqnorm(neo1hsample$miss_distance, col = 'red')
qqline(neo1hsample$miss_distance)
qqnorm(neo1nhsample$miss_distance, col = 'green')
qqline(neo1nhsample$miss_distance)
outlierKD2(neo1hsample$miss_distance)
#Given that there is just too much data, im going to create random samples -> everyone can replicate
set.seed(999)
neo1hsample = neo1h[ sample(nrow(neo1h), 100), ]
neo1nhsample = neo1nh[ sample(nrow(neo1nh), 100), ]
# mlbsample2 = mlb[ sample(nrow(mlb),20), ] from zt r file in class
#Same visualization stuff again on samples...
library(ggplot2)
hist(neo1hsample$miss_distance)
hist(neo1nhsample$miss_distance)
qqnorm(neo1hsample$miss_distance, col = 'red')
qqline(neo1hsample$miss_distance)
qqnorm(neo1nhsample$miss_distance, col = 'green')
qqline(neo1nhsample$miss_distance)
outlierKD2(neo1hsample, neo1hsample$miss_distance)
#Given that there is just too much data, im going to create random samples -> everyone can replicate
set.seed(999)
neo1hsample = neo1h[ sample(nrow(neo1h), 100), ]
neo1nhsample = neo1nh[ sample(nrow(neo1nh), 100), ]
# mlbsample2 = mlb[ sample(nrow(mlb),20), ] from zt r file in class
#Same visualization stuff again on samples...
library(ggplot2)
hist(neo1hsample$miss_distance)
hist(neo1nhsample$miss_distance)
qqnorm(neo1hsample$miss_distance, col = 'red')
qqline(neo1hsample$miss_distance)
qqnorm(neo1nhsample$miss_distance, col = 'green')
qqline(neo1nhsample$miss_distance)
outlierKD2(neo1hsample, neo1hsample$miss_distance)
outlierKD2(neo1nhsample, neo1nhsample$miss_distance)
#Given that there is just too much data, im going to create random samples -> everyone can replicate
set.seed(999)
neo1hsample = neo1h[ sample(nrow(neo1h), 100), ]
neo1nhsample = neo1nh[ sample(nrow(neo1nh), 100), ]
# mlbsample2 = mlb[ sample(nrow(mlb),20), ] from zt r file in class
#Same visualization stuff again on samples...
library(ggplot2)
hist(neo1hsample$miss_distance)
hist(neo1nhsample$miss_distance)
qqnorm(neo1hsample$miss_distance, col = 'red')
qqline(neo1hsample$miss_distance)
qqnorm(neo1nhsample$miss_distance, col = 'green')
qqline(neo1nhsample$miss_distance)
#cool, no outliers, variables are closely normally distributed and samples are of the same size
outlierKD2(neo1hsample, neo1hsample$miss_distance)
outlierKD2(neo1nhsample, neo1nhsample$miss_distance)
#Now on to the tests
#Confidence Intervals 95%
t.test(neo1hsample$miss_distance, conf.level = 0.95)
#Confidence Intervals 95%
t.test(neo1hsample$miss_distance, conf.level = 0.95)
t.test(neo1nhsample$miss_distance, conf.level = 0.95)
#Confidence Intervals 95%
t.test(neo1hsample$miss_distance, conf.level = 0.95)
t.test(neo1nhsample$miss_distance, conf.level = 0.95)
#The intervals do overlap
#Lets try again with a much tighter confidence level
t.test(neo1hsample$miss_distance, conf.level = 0.99)
t.test(neo1nhsample$miss_distance, conf.level = 0.99)
#Confidence Intervals 95%
t.test(neo1hsample$miss_distance, conf.level = 0.95)
t.test(neo1nhsample$miss_distance, conf.level = 0.95)
#The intervals do overlap
#Lets try again with a much tighter confidence level
t.test(neo1hsample$miss_distance, conf.level = 0.99)
t.test(neo1nhsample$miss_distance, conf.level = 0.99)
#As expected, the intervals overlap even to a much greater degree
#Now on to the comparison of both of the samples
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance)
t.test()
?t.test()
#Confidence Intervals 95%
t.test(neo1hsample$miss_distance, conf.level = 0.95)
t.test(neo1nhsample$miss_distance, conf.level = 0.95)
#The intervals do overlap
#Lets try again with a much tighter confidence level
t.test(neo1hsample$miss_distance, conf.level = 0.99)
t.test(neo1nhsample$miss_distance, conf.level = 0.99)
#As expected, the intervals overlap even to a much greater degree
#Now on to the comparison of both of the samples
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance)
# A P-value of 30% on a two-tailed test
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance, alternative = 'greater')
#Confidence Intervals 95%
t.test(neo1hsample$miss_distance, conf.level = 0.95)
t.test(neo1nhsample$miss_distance, conf.level = 0.95)
#The intervals do overlap
#Lets try again with a much tighter confidence level
t.test(neo1hsample$miss_distance, conf.level = 0.99)
t.test(neo1nhsample$miss_distance, conf.level = 0.99)
#As expected, the intervals overlap even to a much greater degree
#Now on to the comparison of both of the samples
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance)
# A P-value of 30% on a two-tailed test
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance, alternative = c('greater'))
#Confidence Intervals 95%
t.test(neo1hsample$miss_distance, conf.level = 0.95)
t.test(neo1nhsample$miss_distance, conf.level = 0.95)
#The intervals do overlap
#Lets try again with a much tighter confidence level
t.test(neo1hsample$miss_distance, conf.level = 0.99)
t.test(neo1nhsample$miss_distance, conf.level = 0.99)
#As expected, the intervals overlap even to a much greater degree
#Now on to the comparison of both of the samples
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance)
# A P-value of 30% on a two-tailed test
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance, alternative = c('less'))
#Confidence Intervals 95%
t.test(neo1hsample$miss_distance, conf.level = 0.95)
t.test(neo1nhsample$miss_distance, conf.level = 0.95)
#The intervals do overlap
#Lets try again with a much tighter confidence level
t.test(neo1hsample$miss_distance, conf.level = 0.99)
t.test(neo1nhsample$miss_distance, conf.level = 0.99)
#As expected, the intervals overlap even to a much greater degree
#Now on to the comparison of both of the samples
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance)
# A P-value of 30% on a two-tailed test
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance, alternative = c('less'))
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance, alternative = c('greater'))
#Confidence Intervals 95%
t.test(neo1hsample$miss_distance, conf.level = 0.95)
t.test(neo1nhsample$miss_distance, conf.level = 0.95)
#The intervals do overlap
#Lets try again with a much tighter confidence level
t.test(neo1hsample$miss_distance, conf.level = 0.99)
t.test(neo1nhsample$miss_distance, conf.level = 0.99)
#As expected, the intervals overlap even to a much greater degree
#Now on to the comparison of both of the samples
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance)
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance, conf.level = 0.99)
# A P-value of 30% on a two-tailed test
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance, alternative = c('less'))
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance, alternative = c('greater'))
#Confidence Intervals 95%
t.test(neo1hsample$miss_distance, conf.level = 0.95)
t.test(neo1nhsample$miss_distance, conf.level = 0.95)
#The intervals do overlap
#Lets try again with a much tighter confidence level
t.test(neo1hsample$miss_distance, conf.level = 0.99)
t.test(neo1nhsample$miss_distance, conf.level = 0.99)
#As expected, the intervals overlap even to a much greater degree
#Now on to the comparison of both of the samples
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance)
t.test(neo1hsample$miss_distance, neo1nhsample$miss_distance, conf.level = 0.99)
# A P-value of 30% on a two-tailed test
factor(neo1$hazardous)
factor(neo1$hazardous)
contable = table(neo1$hazardous, neo1$miss_distance)
factor(neo1$hazardous)
contable = table(neo1$hazardous, neo1$miss_distance)
contable
factor(neo1$hazardous)
#neo1 = neo1(neo1$miss_distance, bin=cut())
neo1$miss_distance
#neo1 = neo1(neo1$miss_distance, bin=cut())
summary(neo1$miss_distance)
#neo1 = neo1(neo1$miss_distance, bin=cut(0,100))
neo1$miss_distance = neo1$miss_distance / 1000
#neo1 = neo1(neo1$miss_distance, bin=cut(0,100))
neo1$miss_distance = neo1$miss_distance / 1000
neo1$miss_distance
#neo1 = neo1(neo1$miss_distance, bin=cut(0,100))
neo1$miss_distance = neo1$miss_distance / 1000
neo1$miss_distance
summary(neo1$miss_distance)
#neo1 = neo1(neo1$miss_distance, bin=cut(0,100))
neo1$miss_distance = neo1$miss_distance * 1000
neo1$miss_distance
summary(neo1$miss_distance)
#neo1 = neo1(neo1$miss_distance, bin=cut(0,100))
neo1$miss_distance = neo1$miss_distance * 1000
neo1$miss_distance
summary(neo1$miss_distance)
#neo1 = neo1(neo1$miss_distance, bin=cut(0,100))
neo1$miss_distance = neo1$miss_distance * 1000
neo1$miss_distance
summary(neo1$miss_distance)
#neo1 = neo1(neo1$miss_distance, bin=cut(0,100))
neo$miss_distance
#neo1 = neo1(neo1$miss_distance, bin=cut(0,100))
neo1$miss_distance = neo1$miss_distance / 1000000
neo1$miss_distance
summary(neo1$miss_distance)
neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20,30,40,50,60,70))
neotest = data.frame(neo1$miss_distance, bin=cut(0,10,20,30,40,50,60,70))
cut(neo1$miss_distance, 10)
cut(neo1$miss_distance, 10)
hist(neo1$miss_distance)
cut(neo1$miss_distance, 6)
hist(neo1$miss_distance)
cut(neo1$miss_distance, 7)
hist(neo1$miss_distance)
cut(neo1$miss_distance, 7)
ggplot(neo1, aes(neo1$miss_distance))+
geom_histogram()
cut(neo1$miss_distance, 7)
ggplot(neo1, aes(neo1$miss_distance))+
geom_histogram(bins=7)
neo1$miss_distance = cut(neo1$miss_distance, 7)
hist(neo1$miss_distance)
neo1$miss_distance = cut(neo1$miss_distance, 7)
neo1$miss_distance
neo1$miss_distance
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
neo1$miss_distance = neo1$miss_distance / 1000000
neo1$miss_distance
summary(neo1$miss_distance)
#Variable is now expressed in millions of km
neo1$miss_distance = cut(neo1$miss_distance
neo1$miss_distance = cut(neo1$miss_distance)
neo1$miss_distance = cut(neo1$miss_distance, o)
neo1$miss_distance = cut(neo1$miss_distance, 0)
neo1$miss_distance = cut(neo1$miss_distance)
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
neo1$miss_distance = neo$miss_distance
#Given that there is just too much data, im going to create random samples -> everyone can replicate
set.seed(999)
neo1hsample = neo1h[ sample(nrow(neo1h), 4000), ]
neo1nhsample = neo1nh[ sample(nrow(neo1nh), 4000), ]
# mlbsample2 = mlb[ sample(nrow(mlb),20), ] from zt r file in class
#Same visualization stuff again on samples...
library(ggplot2)
hist(neo1hsample$miss_distance)
hist(neo1nhsample$miss_distance)
qqnorm(neo1hsample$miss_distance, col = 'red')
qqline(neo1hsample$miss_distance)
qqnorm(neo1nhsample$miss_distance, col = 'green')
qqline(neo1nhsample$miss_distance)
#cool, no outliers, variables are closely normally distributed and samples are of the same size
outlierKD2(neo1hsample, neo1hsample$miss_distance)
outlierKD2(neo1nhsample, neo1nhsample$miss_distance)
#Now on to the tests
#Given that there is just too much data, im going to create random samples -> everyone can replicate
set.seed(999)
neo1hsample = neo1h[ sample(nrow(neo1h), 1000), ]
neo1nhsample = neo1nh[ sample(nrow(neo1nh), 1000), ]
# mlbsample2 = mlb[ sample(nrow(mlb),20), ] from zt r file in class
#Same visualization stuff again on samples...
library(ggplot2)
hist(neo1hsample$miss_distance)
hist(neo1nhsample$miss_distance)
qqnorm(neo1hsample$miss_distance, col = 'red')
qqline(neo1hsample$miss_distance)
qqnorm(neo1nhsample$miss_distance, col = 'green')
qqline(neo1nhsample$miss_distance)
#cool, no outliers, variables are closely normally distributed and samples are of the same size
outlierKD2(neo1hsample, neo1hsample$miss_distance)
outlierKD2(neo1nhsample, neo1nhsample$miss_distance)
#Now on to the tests
#Given that there is just too much data, im going to create random samples -> everyone can replicate
set.seed(999)
neo1hsample = neo1h[ sample(nrow(neo1h), 500), ]
neo1nhsample = neo1nh[ sample(nrow(neo1nh), 500), ]
# mlbsample2 = mlb[ sample(nrow(mlb),20), ] from zt r file in class
#Same visualization stuff again on samples...
library(ggplot2)
hist(neo1hsample$miss_distance)
hist(neo1nhsample$miss_distance)
qqnorm(neo1hsample$miss_distance, col = 'red')
qqline(neo1hsample$miss_distance)
qqnorm(neo1nhsample$miss_distance, col = 'green')
qqline(neo1nhsample$miss_distance)
#cool, no outliers, variables are closely normally distributed and samples are of the same size
outlierKD2(neo1hsample, neo1hsample$miss_distance)
outlierKD2(neo1nhsample, neo1nhsample$miss_distance)
#Now on to the tests
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
#neo1$miss_distance = neo$miss_distance <- to reset
neo1$miss_distance = cut(neo1$miss_distance, 5)
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
#neo1$miss_distance = neo$miss_distance <- to reset
contable = table(neo1$miss_distance, neo1$hazardous)
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
#neo1$miss_distance = neo$miss_distance <- to reset
contable = table(neo1$miss_distance, neo1$hazardous)
contable
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
#neo1$miss_distance = neo$miss_distance <- to reset
contable = table(neo1$miss_distance, neo1$hazardous)
contable
chitest = chisq.test(contable)
chitest
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
#neo1$miss_distance = neo$miss_distance <- to reset
contable = table(neo1$miss_distance, neo1$hazardous)
contable
chitest = chisq.test(contable)
chitest
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
#neo1$miss_distance = neo$miss_distance <- to reset
factor(neo1$hazardous)
contable = table(neo1$miss_distance, neo1$hazardous)
contable
chitest = chisq.test(contable)
chitest
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
#neo1$miss_distance = neo$miss_distance <- to reset
neo1$miss_distance = cut(neo1$miss_distance, 10)
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
neo1$miss_distance = neo$miss_distance
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
#neo1$miss_distance = neo$miss_distance
neo1$miss_distance = cut(neo1$miss_distance, 10)
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
#neo1$miss_distance = neo$miss_distance <- to reset
factor(neo1$hazardous)
contable = table(neo1$miss_distance, neo1$hazardous)
contable
chitest = chisq.test(contable)
chitest
anovatest = aov(neo1$miss_distance ~ neo1$hazardous)
anovatest
anovatest = aov(neo1$miss_distance ~ neo1$hazardous, neo1)
anovatest
factor(neo1$hazardous)
factor(neo1$hazardous)
str(neo1)
?if()
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
#neo1$miss_distance = neo$miss_distance <- to reset
factor(neo1$hazardous)
contable = table(neo1$miss_distance, neo1$hazardous)
contable
chitest = chisq.test(contable)
chitest
anovatest = aov(neo1$miss_distance ~ neo1$hazardous, neo1)
anovatest
as.interger(as.logical(neo1$hazardous))
neo1$hazardous = as.interger(as.logical(neo1$hazardous))
neo1$hazardous = as.integer(as.logical(neo1$hazardous))
neo1$hazardous = as.integer(as.logical(neo1$hazardous))
anovatest = aov(neo1$miss_distance ~ neo1$hazardous, neo1)
anovatest
#neo1 = neo1(neo1$miss_distance, bin=cut(0,10,20))
#neo1$miss_distance = neo$miss_distance <- to reset
factor(neo1$hazardous)
contable = table(neo1$miss_distance, neo1$hazardous)
contable
chitest = chisq.test(contable)
chitest
?aov()
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
# bikeorig = data.frame(read.csv("bikedata.csv"))
bikeorig = api_rfit("BikeShare")
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
bikeorig = data.frame(read.csv("bikedata.csv"))
#bikeorig = api_rfit("BikeShare")
# bike = subset(bikeorig, select = -c(Date, Casual.Users, Registered.Users)) # remove irrelevant columns
bike = subset(bikeorig, select = -c(Date, Casual_Users, Registered_Users)) # remove irrelevant columns
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
bikeorig = data.frame(read.csv("bikedata.csv"))
#bikeorig = api_rfit("BikeShare")
bike = subset(bikeorig, select = -c(Date, Casual.Users, Registered.Users)) # remove irrelevant columns
bike = subset(bikeorig, select = -c(Date, Casual_Users, Registered_Users)) # remove irrelevant columns
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
bikeorig = data.frame(read.csv("bikedata.csv"))
#bikeorig = api_rfit("BikeShare")
bike = subset(bikeorig, select = -c(Date, Casual.Users, Registered.Users)) # remove irrelevant columns
#bike = subset(bikeorig, select = -c(Date, Casual_Users, Registered_Users)) # remove irrelevant columns
colnames(bike)[4:11] = c("Day","Workday","Weather","TempF","TempFF","Humidity","Wind","Tusers") # rename some columns
bike16 = subset(bike, bike$Hour == 16) # with only Hour-16 data. All columns are numerical
nrow(bike16)
bike16$Hour = NULL # Hour has only one value '16' now. No need to keep this column.
bike16$TempFF = NULL # TempFF is highly correlated with TempF. Drop one.
bike_final = bike16
bike_final$Season = factor(bike16$Season)
bike_final$Holiday = factor(bike16$Holiday)
bike_final$Day = factor(bike16$Day)
bike_final$Workday = factor(bike16$Workday)
bike_final$Weather = factor(bike16$Weather)
str(bike_final) # Same as bike16 except some columns are now factor level.
?cor()
corrplot(cor(bike_final))
loadPkg("corrplot")
corrplot(cor(bike_final))
loadPkg("corrplot")
x = cor(bike_final)
loadPkg("corrplot")
x = cor(bike_final[c(6:9)])
corrplot(x)
lm3 = lm(Total.Users ~ Temperature.F+Humidity+Wind.Speed, bike16)
lm3 = lm(Total.Users ~ Temperature.F+Humidity+Wind.Speed, bike16)
lm3 = lm(Total.Users ~ Temperature.F+Humidity+Wind.Speed, bike)
# some of common options (and the defaults) are:
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right',
library(ezids)
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
options(scientific=T, digits = 3)
# options(scipen=9, digits = 3)
# ‘scipen’: integer. A penalty to be applied when deciding to print numeric values in fixed or exponential notation.  Positive values bias towards fixed and negative towards scientific notation: fixed notation will be preferred unless it is more than ‘scipen’ digits wider.
# use scipen=999 to prevent scientific notation at all times
bikeorig = data.frame(read.csv('bikedata.csv'))
bike = bikeorig[-c(1,12,13)]
names(bike)[4:6] = c('Day','Workday','Weather')
names(bike)
str(bike)
bike16 = subset(bike, bike$Hour == 16)
nrow(bike16)
pairs(bike_final, main = 'Pairs plot of bike_final data (n=730)')
loadPkg("corrplot")
bike16_num = cor(bike16[c(7:11)])
corrplot.mixed(bike16_num)
lm1 = lm(Total.Users ~ Temperature.F, bike16)
xkablevif(lm1)
summary(lm1)
lm2 = lm(Total.Users ~ Temperature.F+Humidity, bike16)
xkablevif(lm2)
summary(lm2)
lm3 = lm(Total.Users ~ Temperature.F+Humidity+Wind.Speed, bike16)
xkablevif(lm3)
summary(lm3)
confint(lm3)
anova = anova(lm1,lm2,lm3)
anova
lm1 = lm(Total.Users ~ Temperature.F, bike16)
xkablevif(lm1)
summary(lm1)
lm1$coefficients
lm1 = lm(Total.Users ~ Temperature.F, bike16)
xkablevif(lm1)
summary(lm1)
loadPkg("corrplot")
bike16_num = cor(bike16[c(7:11)])
corrplot(bike16_num)
loadPkg("corrplot")
bike16_num = cor(bike16[c(7:11)])
corrplot.mixed(bike16_num)
lm1 = lm(Total.Users ~ Temperature.Feels.F, bike16)
xkablevif(lm1)
summary(lm1)
lm1 = lm(Total.Users ~ Temperature.F, bike16)
lm1 = lm(Total.Users ~ Temperature.F, bike16)
xkablevif(lm1)
summary(lm1)
lm1 = lm(Total.Users ~ Temperature.Feels.F, bike16)
xkablevif(lm1)
summary(lm1)
lm2 = lm(Total.Users ~ Temperature.Feels.F+Humidity, bike16)
xkablevif(lm2)
summary(lm2)
lm3 = lm(Total.Users ~ Temperature.Feels.F+Humidity+Wind.Speed, bike16)
xkablevif(lm3)
summary(lm3)
confint(lm3)
anova = anova(lm1,lm2,lm3)
anova
lm2 = lm(Total.Users ~ Temperature.Feels.F+Temperature.F, bike16)
xkablevif(lm2)
summary(lm2)
lm3 = lm(Total.Users ~ Temperature.Feels.F+Humidity+Wind.Speed, bike16)
xkablevif(lm3)
summary(lm3)
lm3 = lm(Total.Users ~ Temperature.Feels.F+Humidity+Wind.Speed, bike16)
xkablevif(lm3)
summary(lm3)
lm2 = lm(Total.Users ~ Temperature.Feels.F+Humidity, bike16)
xkablevif(lm2)
summary(lm2)
confint(lm3)
anova = anova(lm1,lm2,lm3)
anova
loadPkg("corrplot")
bike16_num = cor(bike16[c(7:11)])
corrplot(bike16_num, method = "number", type="upper")
