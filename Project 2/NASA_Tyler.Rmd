---
title: "DATS 6101 Team 1 - Project 1"
author: "Tyler Wallett, Anushka Vuppala and David Li"
# date: "today"
date: "`r Sys.Date()`"
output: 
  rmdformats::readthedown:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
    
---
```{r init, include=F}
library(tidyverse)
library(ezids)
```
# Introduction
<span style="color: Blue;"> Our research topic aims to perform explorartory data analysis on the Nearest Earth Objects (NEO) dataset recorded by NASA. This particular dataset includes thousands of labeled observations, over the last 22 years, across multiple attributes that each aim to describe a specific object. Borrowing from the humor of the recent film *Don’t Look Up* by Adam Mckay and NASA’s success in the Double Asteroid Redirection Test (DART) mission, we thought that further describing and exploring this dataset would be opportune.</span> 

The EDA performed can help with the early detection of an asteroid. With the early detection, NASA can take quick remedies to help eliminate the threat. NASA’s DART mission (Double Asteroid Redirection Test) was done for the same purpose. It was designed to deflect an asteroid with a certain momentum by hitting it head-on or attempting to slow it down. More can be read online from this [article](https://en.wikipedia.org/wiki/Double_Asteroid_Redirection_Test).

According to NASA’s [official documentation](https://cneos.jpl.nasa.gov/about/neo_groups.html), a PHA is technically termed using parameters that measure the asteroid’s characteristics and then make a decision if the asteroid is considered hazardous based on certain thresholds. Specifically, all asteroids with an Earth Minimum Orbit intersection Distance (MOID) of 0.05 au or less and an absolute magnitude (H) of 22.0 or less are considered Potentially Hazardous Asteroids (PHAs). In other words, asteroids that can’t get any closer to the Earth (i.e., MOID) than 0.05 au (roughly 7,480,000km) or are smaller than about 140m in diameter (i.e., H=22.0) are not considered PHAs.
 
The current dataset that we have contains 90,000 rows. Each row represents a NEO identified by an ID and name. Out of these 90,000 rows, 9,000 of them are hazardous and 81,000 of them are non-hazardous. This dataset does not contain null values. Apart from the hazardous target variable, our dataset contains 5 numerical variables that can help identify if the asteroid is hazardous or not. These 5 variables are:

1.	est_diameter_min (km) – estimated minimum diameter of the NEO
1.	est_diameter_max (km) – estimated maximum diameter of the NEO
1.	relative_velocity – the velocity (in km/seconds) with which the NEO was travelling with respect to Earth 
1.	miss_distance – distance (in km) by which the asteroid missed the Earth’s surface
1.	absolute_magnitude (H) – signifies the brightness of the asteroid

Out of these 5 variables, we have 3 variables that play a primary role in determining if the asteroid was harmful or not. Those are:

1.	relative_velocity
1.	miss_distance
1.	absolute_magnitude

Throughout the rest of this RMD file, we go over each of these 3 variables in complete depth to answer our SMART question – what are some of the statistical characteristics of Nearest Earth Objects, over the last 22 years, in terms of relative velocity, miss distance and absolute magnitude, that make them hazardous or not?


```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# use scipen=999 to prevent scientific notation at all times
```


# Let's explore the dataset
```{r import_data, results='markup', echo=FALSE}
neo <- data.frame(read.csv("neo.csv", header = TRUE))
```
Displaying the structure of the data:
```{r, results='markup', echo=FALSE}
print(str(neo))
```
Displaying the first 6 rows of the dataset:
```{r, results='markup', echo=FALSE}
print(head(neo))
```
The number of NA values in the dataset => `r sum(is.na(neo))`


Now, we split the dataset into 2 dataframes - one for hazardous and other for non-hazardous. This is to ease out the tests performed.

```{r split dataset, results='markup', echo=FALSE}
hazardous = neo %>% filter(hazardous=="True")
non_hazardous = neo %>% filter(hazardous=="False")
```
The dimensions of hazardous asteroids dataframe: `r dim(hazardous)`

The dimensions of non_hazardous asteroids dataframe: `r dim(non_hazardous)`

# Performing measures of central tendency using Summary

Summary of all asteroids is as follows:
```{r summary, results='markup', echo=FALSE}
summary(neo)
```

# Splitting of dataset
```{r, results='markup'}
set.seed(123)

neo_variables = (neo %>% select(est_diameter_min, est_diameter_max, relative_velocity, absolute_magnitude, miss_distance, hazardous))
neo_variables$hazardous[neo_variables$hazardous == "True"] <- 1
neo_variables$hazardous[neo_variables$hazardous == "False"] <- 0
neo_variables$hazardous = as.numeric(neo_variables$hazardous)

library(smotefamily)

smote = SMOTE(neo_variables[1:5], neo_variables$hazardous)
newdata = smote$data
newdata = newdata %>% rename(hazardous=class)
newdata$hazardous = as.numeric(newdata$hazardous)

smp_size <- floor(0.75 * nrow(newdata))

## set the seed to make your partition reproducible
set.seed(222)
train_data_size <- sample(seq_len(nrow(newdata)), size = smp_size)


nasa_train.labels = newdata[train_data_size,c("hazardous")]
nasa_test.labels = newdata[-train_data_size,c("hazardous")]

nasa_train <- newdata[train_data_size,]
nasa_test <- newdata[-train_data_size,]

nasa_train = scale(nasa_train[,1:5], center = TRUE, scale = TRUE)
nasa_test = scale(nasa_test[,1:5], center = TRUE, scale = TRUE)

# Simple model
library(class)
loadPkg("gmodels")
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")

knn.5 <- knn(train=nasa_train, test=nasa_test, cl=nasa_train.labels, k=5)
print(100 * sum(nasa_test.labels == knn.5)/NROW(nasa_test.labels))
confusionMatrix(knn.5, as.factor(nasa_test.labels) )
```

#Feature Selection 

Before doing the modeling section of our analysis, we decided to conduct a feature selection. A feature selection will help us to properly identify those features, or variables, that are most important to include in our models. In this manner, we can get the best model with the given data. To do identify these features, we decided to use three relevant feature selection models, these are: Spearman Correlation Plot, Lasso Regression and Bayesian Information Criterion (BIC) plot. Each feature selection model will interpret the data in their own manner and yield a different conclusion as to which feature is best to use. Therefore, if there is a feature that is indeed important, it should, in theory, be noticeable across each of these feature selection models.

## Feature Selection: Spearman Correlation Plot

Spearman Correlation Plots identify each correlation coefficient for ranked variables. A perk of using Spearmans Correlation Plot is that we can notice which relationships might result in multicollinearity, meaning that one independent variable being highly or absolutely correlated with another independent variable. Luckily for us, we do notice some substantial multicollinearity not only with one variable but with two in our first Spearman Correlation Plot. The variables `est_diameter_min` and `est_diameter_max` are perfectly positively correlated with each other, and perfectly negatively correlated with the variable `absolute_magnitude`. So, for the previously mentioned reasons, we will re-do our Spearman Correlation Plot without both of these variables. Thus, we are left with `relative_velocity`, `miss_distance` and `absolute_magnitude` as our independent variables. As for the interpretation with our dependent variable `hazardous` this second Spearman Correlation Plot reveals to us that `absolute_magnitude` has the highest degree of influence with a ***-0.37** coefficient, then `relative_velocity` with a **0.18** coefficient, and lastly `miss_distance` with virtualy no degree of influence **0.04**.

```{r, results='markup'}
library(corrplot)

neo_cor <- select(neo, c(3:6,9,10))
neo_cor$hazardous = as.numeric(as.logical(neo_cor$hazardous))

corrplot(cor(neo_cor, method ='spearman'), method = "number", title = "Spearman Correlation", outline = TRUE, mar = c(1,1,1,1))

neo_cor2 <- select(neo, c(4:6,9,10))
neo_cor2$hazardous = as.numeric(as.logical(neo_cor2$hazardous))

corrplot(cor(neo_cor2, method ='spearman'), method = "number", title = "Spearman Correlation", outline = TRUE, mar = c(1,1,1,1))

neo_cor3 <- select(neo, c(5:6,9,10))
neo_cor3$hazardous = as.numeric(as.logical(neo_cor3$hazardous))

corrplot(cor(neo_cor3, method ='spearman'), method = "number", title = "Spearman Correlation", outline = TRUE, mar = c(1,1,1,1))

library('ggplot2')
library('GGally')
ggpairs(neo_cor3)
```

## Feature Selection: Lasso Regression 

Next up in our feature selection models, we conducted a Lasso Regression. Lasso Regressions are elastic-net regularization methods that seek to add a penalty term for each independent coefficient in the model. Particularly, a Lasso Regression will add a L-1 penalty term, which is similar to a Manhattan distance, for varying degrees of lambda until each coefficient is reduced to zero. Ultimately, the logic behind a Lasso Regression is that the last coefficient to be converted to zero tends to be the most significant. Also, for this particular case since our dependent variable is categorical, we used binomial deviance as our measure to find the smallest degree of error by the log of lambda. As can be visualized in our first graph, the smallest degree of binomial deviance is when log lambda is equal to **7**, hence this represents a good starting point for our Lasso Regression. As can be noticed in our second graph, the coefficients start at the smalles point of error and eventually, as log lambda increases, all the coefficients turn to zero. However, `absolute_magnitude` by a landslide appeared to be the most significant coefficient as, unlike `miss_distance` and `relative_velocity`, it was the last to turn to zero. Which basically confirms our results in the previous Spearman Correlation Plot.

```{r, results='markup'}

library(glmnet)

newdata_lasso <- newdata

newdata_lasso$hazardous <- as.factor(newdata_lasso$hazardous)

y = newdata_lasso[,"hazardous"]

newdata_lasso_x <- scale(newdata_lasso[1:5], center = TRUE, scale = TRUE)
newdata_lasso_x <- data.frame(newdata_lasso)

x = model.matrix(hazardous ~ relative_velocity + absolute_magnitude + miss_distance, data=newdata_lasso)[,-1]

cv.lambda.lasso <- cv.glmnet(x=x, y=y, family = "binomial", alpha = 1)

plot(cv.lambda.lasso)   
title(main = 'Cross-Validation of Binomial Deviance vs. Log Lambda', line = 0.2)

cv.lambda.lasso

library(plotmo)
plot_glmnet(cv.lambda.lasso$glmnet.fit, 
     "lambda", label =TRUE, main = 'Lasso Regression')
```

## Feature Selection: Bayesian Information Criterion (BIC) plot

Last in the line-up of our feature selection models, we decided to conduct a BIC plot. A BIC plot shows us the lowest Bayesian Information Criterion point for each possible model. The logic behind the plot is that the lowest BIC possible represents the best possible the model. From our graph, we can notice that for the lowest BIC possible of **-87,000** the best model is that which includes all of the independent variables. And curiously enough, for each of the other lowest possible BIC levels, `absolute_magnitude` is included.

```{r, results='markup'}

newdata_glm <- newdata
newdata_glm <- select(newdata_glm, c(3:6))
newdata_glm$hazardous <- as.factor(newdata_glm$hazardous)

loadPkg("leaps")
reg.leaps <- regsubsets(hazardous~., data = newdata_glm, nbest = 1, method = "exhaustive")
plot(reg.leaps, scale = "bic", main = "BIC", las =1)

```

Thus, from our feature selections models, we have gathered that the best possible model is that which uses all of the independent variables, and that the most significant variable is `absolute_magnitude`, which recall represents the degree luminosity, calculated by its distance orbited to the sun, of the nearest earth objects.

#Logistic Regression 

## Interpretation of coefficients

The equation from the Logistic Regression model: 

logit(y(`hazardous`)) = 1.89e+01 + 1.89e+01* (`relative_velocity`) - 8.65e-01* (`absolute_magnitude`) - 1.50e-08* (`miss_distance`)

As hinted from our feature selection, all of the independent variable's coefficients are statistically significant. To make our interpretation of the coefficients even simpler, we decided that it would be best to describe them in terms of their odds, not log odds. Therefore, from our results we can observe that the odds of a neo being hazardous increases when its relative velocity increases, its absolute magnitude decreases and its miss distance decreases. 


```{r, results='markup'}

glm.nasa <- glm(formula = hazardous ~ ., data = newdata_glm, family = binomial)

summary(glm.nasa)

```

#Logistic Regression: Evaluation Metrics


* Confusion Matrix: With the addition of SMOTE to our dataframe we where able to improve our confusion matrix results to yield a higher recall score. From this particular model, the accuracy turned out to be **85.30%**, specificity (FPR) **91.16%** and Recall (TPR) **80.73%**. Therefore, the model did a good job at predicting actual true hazardous neo's, as well as an even better job at predicting actual not hazardous neo's.

* McFadden's value: The McFadden value, or pseudo r^2, was of **0.40**. So the model was able to interpret about 40% of the variance in the outcome of `hazardous`.


* Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC): The ROC curve appeared to be very steep indicating that it had a good True-Positive Rate (TPR) by False-Positive Rate (FPR), indicating that it performed substantially well. And lastly, the AUC was of **0.877** indicating that this was a good model to accept.


```{r, results='markup'}
set.seed(123)
#Confusion matrix
loadPkg("ModelMetrics")
xkabledply( confusionMatrix(actual= glm.nasa$y, predicted= glm.nasa$fitted.values), title = "Confusion matrix from Logit Model" )

#McFadden's value
loadPkg("pscl") 
model1r2 = pR2(glm.nasa)
model1r2

#Receiver-Operator-Characteristic (ROC) curve and Area-Under-Curve (AUC)
loadPkg("pROC")
prob1 = predict(glm.nasa, type ='response')
glm.nasa$prob = prob1
h = roc(hazardous ~ prob1, newdata_glm)
auc(h)
plot(h, main = 'ROC: Logistic Regression Model')

glm.nasa$coefficients

```


#Logistic Regression: Sample predictions



```{r, results='markup'}

glm_plot1 <- with(neo_cor3, data.frame(relative_velocity = mean(relative_velocity), miss_distance = mean(miss_distance), absolute_magnitude = rep(seq(from = 9, to = 34, length.out = 100), 2)))

glm_plot2 <- cbind(glm_plot1, predict(glm.nasa, newdata = glm_plot1, type = "link", se = TRUE))
glm_plot2 <- within(glm_plot2, {
    PredictedProb <- plogis(fit)
    LL <- plogis(fit - (1.96 * se.fit))
    UL <- plogis(fit + (1.96 * se.fit))
})

ggplot(glm_plot2, aes(x = absolute_magnitude, y = PredictedProb)) + geom_ribbon(aes(ymin = LL,
    ymax = UL), alpha = 0.2) + geom_line(size = 1, color = 'red') + labs(title = "Logistic model of predicted probability vs absolute_magnitude")

```


#Sample Predictions

* Prediction #1:

* Prediction #2:

```{r, results='markup'}

sampleprediction1 = data.frame(relative_velocity = 17.38, absolute_magnitude = 17.1, miss_distance = 1.2417e+8)

sampleprediction2 = data.frame(relative_velocity = 21.80, absolute_magnitude = 18.02, miss_distance = 2.543e+8)

predict(glm.nasa, newdata = sampleprediction1, type = 'response')

predict(glm.nasa, newdata = sampleprediction2, type = 'response')

```








# References:

- Kaggle Dataset (Kaggle):
Vani, S. (2022, June 17). NASA - Nearest Earth objects. Kaggle. Retrieved November 2, 2022, from https://www.kaggle.com/datasets/sameepvani/nasa-nearest-earth-objects 
- Center for Near Earth Objects Studies (CNEOS):
NASA. (n.d.). Neo basics. NASA. Retrieved November 2, 2022, from https://cneos.jpl.nasa.gov/about/neo_groups.html 
- NASA (NASA):
Bardan, R. (2022, October 11). NASA confirms Dart Mission Impact Changed Asteroid's motion in space. NASA. Retrieved November 2, 2022, from https://www.nasa.gov/press-release/nasa-confirms-dart-mission-impact-changed-asteroid-s-motion-in-space 
- Araujo, R. A. N., & Winter, O. C. (2014). Near-Earth asteroid binaries in close encounters with the Earth. Astronomy & Astrophysics, 566, A23.
- Peter O. K. Krehl (2008). History of Shock Waves, Explosions and Impact: A Chronological and Biographical Reference. Springer Science & Business Media. p. 404. ISBN 978-3-540-30421-0.
- Tonry, J. L. (2010). An early warning system for asteroid impact. Publications of the Astronomical Society of the Pacific, 123(899), 58.