---
title: "DATS 6101 Team 1 - Project 1"
author: "Tyler Wallett, Anushka Vuppala and David Li"
# date: "today"
date: "`r Sys.Date()`"
output: 
  rmdformats::readthedown:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
    
---
```{r init, include=F}
library(tidyverse)
library(ezids)
library(class)
loadPkg("gmodels")
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")
```
# Introduction
<span style="color: Blue;"> Our research topic aims to perform explorartory data analysis on the Nearest Earth Objects (NEO) dataset recorded by NASA. This particular dataset includes thousands of labeled observations, over the last 22 years, across multiple attributes that each aim to describe a specific object. Borrowing from the humor of the recent film *Don’t Look Up* by Adam Mckay and NASA’s success in the Double Asteroid Redirection Test (DART) mission, we thought that further describing and exploring this dataset would be opportune.</span> 

The EDA performed can help with the early detection of an asteroid. With the early detection, NASA can take quick remedies to help eliminate the threat. NASA’s DART mission (Double Asteroid Redirection Test) was done for the same purpose. It was designed to deflect an asteroid with a certain momentum by hitting it head-on or attempting to slow it down. More can be read online from this [article](https://en.wikipedia.org/wiki/Double_Asteroid_Redirection_Test).

According to NASA’s [official documentation](https://cneos.jpl.nasa.gov/about/neo_groups.html), a PHA is technically termed using parameters that measure the asteroid’s characteristics and then make a decision if the asteroid is considered hazardous based on certain thresholds. Specifically, all asteroids with an Earth Minimum Orbit intersection Distance (MOID) of 0.05 au or less and an absolute magnitude (H) of 22.0 or less are considered Potentially Hazardous Asteroids (PHAs). In other words, asteroids that can’t get any closer to the Earth (i.e., MOID) than 0.05 au (roughly 7,480,000km) or are smaller than about 140m in diameter (i.e., H=22.0) are not considered PHAs.
 
The current dataset that we have contains 90,000 rows. Each row represents a NEO identified by an ID and name. Out of these 90,000 rows, 9,000 of them are hazardous and 81,000 of them are non-hazardous. This dataset does not contain null values. Apart from the hazardous target variable, our dataset contains 5 numerical variables that can help identify if the asteroid is hazardous or not. These 5 variables are:

1.	est_diameter_min (km) – estimated minimum diameter of the NEO
1.	est_diameter_max (km) – estimated maximum diameter of the NEO
1.	relative_velocity – the velocity (in km/seconds) with which the NEO was travelling with respect to Earth 
1.	miss_distance – distance (in km) by which the asteroid missed the Earth’s surface
1.	absolute_magnitude (H) – signifies the brightness of the asteroid

Out of these 5 variables, we have 3 variables that play a primary role in determining if the asteroid was harmful or not. Those are:

1.	relative_velocity
1.	miss_distance
1.	absolute_magnitude

Throughout the rest of this RMD file, we go over each of these 3 variables in complete depth to answer our SMART question – what are some of the statistical characteristics of Nearest Earth Objects, over the last 22 years, in terms of relative velocity, miss distance and absolute magnitude, that make them hazardous or not?


```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# use scipen=999 to prevent scientific notation at all times
```


# Let's explore the dataset
```{r import_data, results='markup', echo=FALSE}
neo <- data.frame(read.csv("neo.csv", header = TRUE))
```
Displaying the structure of the data:
```{r, results='markup', echo=FALSE}
print(str(neo))
```
Displaying the first 6 rows of the dataset:
```{r, results='markup', echo=FALSE}
print(head(neo))
```
The number of NA values in the dataset => `r sum(is.na(neo))`


Now, we split the dataset into 2 dataframes - one for hazardous and other for non-hazardous. This is to ease out the tests performed.

```{r split dataset, results='markup', echo=FALSE}
hazardous = neo %>% filter(hazardous=="True")
non_hazardous = neo %>% filter(hazardous=="False")
```
The dimensions of hazardous asteroids dataframe: `r dim(hazardous)`

The dimensions of non_hazardous asteroids dataframe: `r dim(non_hazardous)`

# Performing measures of central tendency using Summary

Summary of all asteroids is as follows:
```{r summary, results='markup', echo=FALSE}
summary(neo)
```



# PROJECT 2

Before we begin any modeling, it is good practice to have a training and test accuracy.

# Sampling of data
## Helper functions
```{r, results='markup'}
Standardization <- function(data) {
  return (scale(data[,1:5], center = TRUE, scale = TRUE))
}

basicKNN5 <- function() {
  knn.5 <- knn(train=nasa_train, test=nasa_test, cl=nasa_train.labels, k=5)
  print(100 * sum(nasa_test.labels == knn.5)/NROW(nasa_test.labels))
  confusionMatrix(knn.5, as.factor(nasa_test.labels), mode="everything")
}
```

Below is the R code of performing the split without any sampling technique used.
We would also be using the training and testing data to check the accuracy of a base KNN model. We would implement this KNN model with the k value equal to 5 for the purpose of comparison between different sampling techniques.

## No sampling technique used:
```{r, results='markup'}
#str(neo)
set.seed(123)

neo_no_sampling = (neo %>% select(est_diameter_min, est_diameter_max, relative_velocity, absolute_magnitude, miss_distance, hazardous))
smp_size <- floor(0.75 * nrow(neo_no_sampling))
train_data_size <- sample(seq_len(nrow(neo_no_sampling)), size = smp_size)


nasa_train.labels = neo_no_sampling[train_data_size,c("hazardous")]
nasa_test.labels = neo_no_sampling[-train_data_size,c("hazardous")]

neo_no_sampling = neo_no_sampling %>% select(est_diameter_min, est_diameter_max, relative_velocity, miss_distance, absolute_magnitude)
nasa_train <- neo_no_sampling[train_data_size,]
nasa_test <- neo_no_sampling[-train_data_size,]

# Standardization
nasa_train = Standardization(nasa_train)
nasa_test = Standardization(nasa_test)

basicKNN5()

```
The above shows an accuracy of 89.5% which initially sounds great. But when we draw a confusion matrix on the above and report other evaluation metrics, we see a 30% Specificity. This is not surprising as the amount of data in minority class (hazardous) is very minimum. 

The next sampling technique we can use is called downsampling. This ensures that the data that we choose has equal proportions of hazardous and non-hazardous asteroids.
For the purpose of implementing downsampling, we will retain all the rows in hazardous and randomly sample equal number of rows from non-hazardous. In other words, we would be bringing down the number of rows in non-hazardous from ~80,000 to ~8,000 rows.

## Downsampling
```{r, results='markup'}
set.seed(123)
non_hazardous = non_hazardous[sample(nrow(non_hazardous),nrow(hazardous)),]
neo_downsampling= rbind(hazardous, non_hazardous)
nrow(neo_downsampling)

## 75% of the sample size
smp_size <- floor(0.75 * nrow(neo_downsampling))

## set the seed to make your partition reproducible
set.seed(123)
train_data_size <- sample(seq_len(nrow(neo_downsampling)), size = smp_size)

nasa_train.labels = neo_downsampling[train_data_size,c("hazardous")]
nasa_test.labels = neo_downsampling[-train_data_size,c("hazardous")]

neo_downsampling = neo_downsampling %>% select(est_diameter_min, est_diameter_max, relative_velocity, miss_distance, absolute_magnitude)
nasa_train <- neo_downsampling[train_data_size,]
nasa_test <- neo_downsampling[-train_data_size,]

# Standardization
nasa_train = Standardization(nasa_train)
nasa_test = Standardization(nasa_test)

basicKNN5()
```
From downsampling result above, we see that the results have become more realisti. In other words, we see that our Specificity rate has increased to 92% which is a great indicator of a great model. However, one biggest disadvantage of downsampling is loss of data. We are training the model with insufficient amount of data.

The next obvious sampling technique is upsampling. One such case of upsampling is SMOTE. Smote created artificial data points to bring up the data points in minority class.

## SMOTE
```{r,results='markup'}
set.seed(123)

neo_smote = (neo %>% select(est_diameter_min, est_diameter_max, relative_velocity, absolute_magnitude, miss_distance, hazardous))
neo_smote$hazardous[neo_smote$hazardous == "True"] <- 1
neo_smote$hazardous[neo_smote$hazardous == "False"] <- 0
neo_smote$hazardous = as.numeric(neo_smote$hazardous)

library(smotefamily)
smote = SMOTE(neo_smote[1:5], neo_smote$hazardous)
newdata = smote$data
newdata = newdata %>% rename(hazardous=class)
newdata$hazardous = as.numeric(newdata$hazardous)


smp_size <- floor(0.75 * nrow(newdata))

## set the seed to make your partition reproducible
set.seed(222)
train_data_size <- sample(seq_len(nrow(newdata)), size = smp_size)


nasa_train.labels = newdata[train_data_size,c("hazardous")]
nasa_test.labels = newdata[-train_data_size,c("hazardous")]

nasa_train <- newdata[train_data_size,]
nasa_test <- newdata[-train_data_size,]

nasa_train = scale(nasa_train[,1:5], center = TRUE, scale = TRUE)
nasa_test = scale(nasa_test[,1:5], center = TRUE, scale = TRUE)

basicKNN5()
```

From the above, we can see that we have finally received a higher rate of Recall. Now, this is only with k=5. Let's explore k value with a defined set of ranges. Ideally, k has a value between 5 and 20. We shall run a for loop to get accuracy of each odd valued k to find the optimal one.

# KNN
```{r, results='markup'}
ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )
set.seed(222)
for (kval in seq(1,18,2)) {
  nasa_pred <- knn(train = nasa_train, test = nasa_test, cl=nasa_train.labels, k=kval)
  cm = confusionMatrix(nasa_pred, as.factor(nasa_test.labels) ) # from caret library
  cmaccu = cm$overall['Accuracy']
  cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics 
  ResultDf = rbind(ResultDf, cmt)
}
xkabledply(ResultDf, "Total Accuracy Summary:")

```

Now, with the accuracies defined for all possible k values, we shall draw a plot and see the accuracies.
```{r, results='markup'}
ggplot(data=ResultDf, aes(x=k, y=Total.Accuracy,group=1)) +
  geom_line(color="#aa0022", size=1.75) +
  geom_point(color="#aa0022", size=3.5) +
  ggtitle("K value against their accuracy in KNN model") +
  labs(x="K value", y="Accuracy of K value") +
  theme(axis.title.y = element_text(size=10, family="Trebuchet MS", color="#666666")) +
  theme(axis.text = element_text(size=14, family="Trebuchet MS")) +
  theme(plot.title = element_text(size=20, family="Trebuchet MS", face="bold", hjust=0, color="#666666"))


```
From the above, we see that when k=9, we get the good accuracy of 87.6%
Please note that despite having higher accuracies beyond k=9, we should keep in mind that having a higher k value leads to overfitting of the model and thus, we need to be mindful when choosing our k value.

Now, taking k=9, we should perform model evaulation.

## KNN model Evaluation
```{r, results='markup'}

knn.9 <- knn(train=nasa_train, test=nasa_test, cl=nasa_train.labels, k=9, prob=TRUE)
print(confusionMatrix(knn.9, as.factor(nasa_test.labels), mode = "everything"))

library(pROC)

print(roc(nasa_test.labels, attributes(knn.9)$prob))

plot(roc(nasa_test.labels, attributes(knn.9)$prob),
     print.thres = T,
     print.auc=T)


```
From the above, we see that the recall we obtain is 80% which is better than all of the above sampling techniques we have used above. In addition to this, we also see that the area under the curve is 0.706. Ideally, anything over 0.8 is considered good fit model. But area under the curve = 0.706 is considered an acceptable model. In conclusion, the KNN model with SMOTE sampling resulted in a good accuracy turnout. In addition to this, when k=11, we get the best accuracy in comparison with the rest.

# Limitations

The `neo.csv` data set posed limitations in the variables, description and dictionary. Since the dataset was obtained from a web-based environment, kaggle, we had insufficient variables, a poor description of the dataset and no data dictionary provided. In terms of the variables provided, it would have been ideal to have one regarding the trajectory towards, or away, from earth, as well as other potentially hazardous, or not hazardous, variables. Nevertheless, we were restricted to just using the three variables that were quantifiable in order to characterize the potential of it being hazardous. In retrospect, just using these three variables might have been an over-simplification in our determination of a hazard. On the other hand, the description of the dataset is very limited given the constraint of using Kaggle. It would have been better if the dataset was obtained straight from a NASA website or API, however this was not possible. It would have been a huge perk to know how these variables are being used by NASA professionals, what characterizes an instance to be recorded multiple times, and why they initially attributed the boolean value for Hazardous. Finally, when it came to providing a data dictionary, the kaggle website did not have one. Thus, we had to do our own research as to what these variables meant, and what they were describing. Therefore, with insufficient variables, a poor description and no data dictionary it was difficult to infer, or fully understand, the root of a hazardous or not hazardous asteroid to fully answer our question.


# References:

- Kaggle Dataset (Kaggle):
Vani, S. (2022, June 17). NASA - Nearest Earth objects. Kaggle. Retrieved November 2, 2022, from https://www.kaggle.com/datasets/sameepvani/nasa-nearest-earth-objects 
- Center for Near Earth Objects Studies (CNEOS):
NASA. (n.d.). Neo basics. NASA. Retrieved November 2, 2022, from https://cneos.jpl.nasa.gov/about/neo_groups.html 
- NASA (NASA):
Bardan, R. (2022, October 11). NASA confirms Dart Mission Impact Changed Asteroid's motion in space. NASA. Retrieved November 2, 2022, from https://www.nasa.gov/press-release/nasa-confirms-dart-mission-impact-changed-asteroid-s-motion-in-space 
- Araujo, R. A. N., & Winter, O. C. (2014). Near-Earth asteroid binaries in close encounters with the Earth. Astronomy & Astrophysics, 566, A23.
- Peter O. K. Krehl (2008). History of Shock Waves, Explosions and Impact: A Chronological and Biographical Reference. Springer Science & Business Media. p. 404. ISBN 978-3-540-30421-0.
- Tonry, J. L. (2010). An early warning system for asteroid impact. Publications of the Astronomical Society of the Pacific, 123(899), 58.






