---
title: "DATS 6101 Team 1 - Project 1"
author: "Tyler Wallett, Anushka Vuppala and David Li"
# date: "today"
date: "`r Sys.Date()`"
output: 
  rmdformats::readthedown:
  html_document:
    code_folding: hide
    number_sections: false
    toc: yes
    toc_depth: 3
    toc_float: yes
  pdf_document:
    toc: yes
    toc_depth: '3'
    
---
```{r init, include=F}
library(tidyverse)
library(ezids)
```
# Introduction
<span style="color: Blue;"> Our research topic aims to perform explorartory data analysis on the Nearest Earth Objects (NEO) dataset recorded by NASA. This particular dataset includes thousands of labeled observations, over the last 22 years, across multiple attributes that each aim to describe a specific object. Borrowing from the humor of the recent film *Don’t Look Up* by Adam Mckay and NASA’s success in the Double Asteroid Redirection Test (DART) mission, we thought that further describing and exploring this dataset would be opportune.</span> 

The EDA performed can help with the early detection of an asteroid. With the early detection, NASA can take quick remedies to help eliminate the threat. NASA’s DART mission (Double Asteroid Redirection Test) was done for the same purpose. It was designed to deflect an asteroid with a certain momentum by hitting it head-on or attempting to slow it down. More can be read online from this [article](https://en.wikipedia.org/wiki/Double_Asteroid_Redirection_Test).

According to NASA’s [official documentation](https://cneos.jpl.nasa.gov/about/neo_groups.html), a PHA is technically termed using parameters that measure the asteroid’s characteristics and then make a decision if the asteroid is considered hazardous based on certain thresholds. Specifically, all asteroids with an Earth Minimum Orbit intersection Distance (MOID) of 0.05 au or less and an absolute magnitude (H) of 22.0 or less are considered Potentially Hazardous Asteroids (PHAs). In other words, asteroids that can’t get any closer to the Earth (i.e., MOID) than 0.05 au (roughly 7,480,000km) or are smaller than about 140m in diameter (i.e., H=22.0) are not considered PHAs.
 
The current dataset that we have contains 90,000 rows. Each row represents a NEO identified by an ID and name. Out of these 90,000 rows, 9,000 of them are hazardous and 81,000 of them are non-hazardous. This dataset does not contain null values. Apart from the hazardous target variable, our dataset contains 5 numerical variables that can help identify if the asteroid is hazardous or not. These 5 variables are:

1.	est_diameter_min (km) – estimated minimum diameter of the NEO
1.	est_diameter_max (km) – estimated maximum diameter of the NEO
1.	relative_velocity – the velocity (in km/seconds) with which the NEO was travelling with respect to Earth 
1.	miss_distance – distance (in km) by which the asteroid missed the Earth’s surface
1.	absolute_magnitude (H) – signifies the brightness of the asteroid

Out of these 5 variables, we have 3 variables that play a primary role in determining if the asteroid was harmful or not. Those are:

1.	relative_velocity
1.	miss_distance
1.	absolute_magnitude

Throughout the rest of this RMD file, we go over each of these 3 variables in complete depth to answer our SMART question – what are some of the statistical characteristics of Nearest Earth Objects, over the last 22 years, in terms of relative velocity, miss distance and absolute magnitude, that make them hazardous or not?


```{r setup, include=FALSE}
# some of common options (and the defaults) are: 
# include=T, eval=T, echo=T, results='hide'/'asis'/'markup',..., collapse=F, warning=T, message=T, error=T, cache=T, fig.width=6, fig.height=4, fig.dim=c(6,4) #inches, fig.align='left'/'center','right', 
# knitr::opts_chunk$set(warning = F, results = "markup", message = F)
knitr::opts_chunk$set(warning = F, results = "hide", message = F)
# knitr::opts_chunk$set(include = F)
# knitr::opts_chunk$set(echo = TRUE)
options(scientific=T, digits = 3) 
# options(scipen=9, digits = 3) 
# use scipen=999 to prevent scientific notation at all times
```


# Let's explore the dataset
```{r import_data, results='markup', echo=FALSE}
neo <- data.frame(read.csv("neo.csv", header = TRUE))
```
Displaying the structure of the data:
```{r, results='markup', echo=FALSE}
print(str(neo))
```
Displaying the first 6 rows of the dataset:
```{r, results='markup', echo=FALSE}
print(head(neo))
```
The number of NA values in the dataset => `r sum(is.na(neo))`


Now, we split the dataset into 2 dataframes - one for hazardous and other for non-hazardous. This is to ease out the tests performed.

```{r split dataset, results='markup', echo=FALSE}
hazardous = neo %>% filter(hazardous=="True")
non_hazardous = neo %>% filter(hazardous=="False")
```
The dimensions of hazardous asteroids dataframe: `r dim(hazardous)`

The dimensions of non_hazardous asteroids dataframe: `r dim(non_hazardous)`

# Performing measures of central tendency using Summary

Summary of all asteroids is as follows:
```{r summary, results='markup', echo=FALSE}
summary(neo)
```



# PROJECT 2
# EDA ENDS
# Splitting and Sampling
# no sampling
```{r, results='markup'}
#str(neo)
set.seed(123)
neo_no_sampling = (neo %>% select(est_diameter_min, est_diameter_max, relative_velocity, absolute_magnitude, miss_distance, hazardous))
smp_size <- floor(0.75 * nrow(neo_no_sampling))
train_data_size <- sample(seq_len(nrow(neo_no_sampling)), size = smp_size)


nasa_train.labels = neo_no_sampling[train_data_size,c("hazardous")]
nasa_test.labels = neo_no_sampling[-train_data_size,c("hazardous")]

neo_no_sampling = neo_no_sampling %>% select(est_diameter_min, est_diameter_max, relative_velocity, miss_distance, absolute_magnitude)
nasa_train <- neo_no_sampling[train_data_size,]
nasa_test <- neo_no_sampling[-train_data_size,]

# Standardization
nasa_train = scale(nasa_train[,1:5], center = TRUE, scale = TRUE)
nasa_test = scale(nasa_test[,1:5], center = TRUE, scale = TRUE)

library(class)
loadPkg("gmodels")
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")
knn.5 <- knn(train=nasa_train, test=nasa_test, cl=nasa_train.labels, k=5)
print(100 * sum(nasa_test.labels == knn.5)/NROW(nasa_test.labels))
confusionMatrix(knn.5, as.factor(nasa_test.labels) )

```

# Downsampling
```{r, results='markup'}
set.seed(123)
non_hazardous = non_hazardous[sample(nrow(non_hazardous),nrow(hazardous)),]
neo_downsampling= rbind(hazardous, non_hazardous)
nrow(neo_downsampling)

## 75% of the sample size
smp_size <- floor(0.75 * nrow(neo_downsampling))

## set the seed to make your partition reproducible
set.seed(123)
train_data_size <- sample(seq_len(nrow(neo_downsampling)), size = smp_size)


nasa_train.labels = neo_downsampling[train_data_size,c("hazardous")]
nasa_test.labels = neo_downsampling[-train_data_size,c("hazardous")]

neo_downsampling = neo_downsampling %>% select(est_diameter_min, est_diameter_max, relative_velocity, miss_distance, absolute_magnitude)
nasa_train <- neo_downsampling[train_data_size,]
nasa_test <- neo_downsampling[-train_data_size,]

# Standardization
nasa_train = scale(nasa_train[,1:5], center = TRUE, scale = TRUE)
nasa_test = scale(nasa_test[,1:5], center = TRUE, scale = TRUE)

library(class)
loadPkg("gmodels")
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")
knn.5 <- knn(train=nasa_train, test=nasa_test, cl=nasa_train.labels, k=5)
print(100 * sum(nasa_test.labels == knn.5)/NROW(nasa_test.labels))
confusionMatrix(knn.5, as.factor(nasa_test.labels) )
```

# Stratified Sampling
# hazardous => 8000  => 1,000
# non_hazardous => 80,000 => 1,000
```{r, results='markup'}
set.seed(123)
neo_stratified = (neo %>% select(est_diameter_min, est_diameter_max, relative_velocity, absolute_magnitude, miss_distance, hazardous))
stratified <- neo_stratified %>%
    group_by(hazardous) %>%
    sample_n(size=1000)

#str(stratified)
stratified = data.frame(stratified)
stratified$hazardous[stratified$hazardous == "True"] <- 1
stratified$hazardous[stratified$hazardous == "False"] <- 0
stratified$hazardous = as.numeric(stratified$hazardous)
## 75% of the sample size
smp_size <- floor(0.75 * nrow(stratified))

## set the seed to make your partition reproducible
set.seed(123)
train_data_size <- sample(seq_len(nrow(stratified)), size = smp_size)


nasa_train.labels = stratified[train_data_size,6]
nasa_test.labels = stratified[-train_data_size,c("hazardous")]

#stratified = stratified %>% select(est_diameter_min, est_diameter_max, relative_velocity, miss_distance, absolute_magnitude)
nasa_train <- stratified[train_data_size,1:5]
nasa_test <- stratified[-train_data_size,1:5]
# Standardization
nasa_train = scale(nasa_train[1:5], center = TRUE, scale = TRUE)
nasa_test = scale(nasa_test[1:5], center = TRUE, scale = TRUE)

library(class)
loadPkg("gmodels")
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")
knn.5 <- knn(train=nasa_train, test=nasa_test, cl=nasa_train.labels, k=5)
print(100 * sum(nasa_test.labels == knn.5)/NROW(nasa_test.labels))
confusionMatrix(knn.5, as.factor(nasa_test.labels) )
```


```{r, results='markup'}
# split and then train


set.seed(222)
neo_anushka = (neo %>% select(est_diameter_min, est_diameter_max, relative_velocity, absolute_magnitude, miss_distance, hazardous))
neo_anushka$hazardous[neo_anushka$hazardous == "True"] <- 1
neo_anushka$hazardous[neo_anushka$hazardous == "False"] <- 0
neo_anushka$hazardous = as.numeric(neo_anushka$hazardous)

smp_size <- floor(0.79 * nrow(neo_anushka))

## set the seed to make your partition reproducible
#set.seed(222)
train_data_size <- sample(seq_len(nrow(neo_anushka)), size = smp_size)


nasa_train.labels = neo_anushka[train_data_size,c("hazardous")]
nasa_test.labels = neo_anushka[-train_data_size,c("hazardous")]

nasa_train <- neo_anushka[train_data_size,]
nasa_test <- neo_anushka[-train_data_size,]

#SMOTE
library(smotefamily)
smote = SMOTE(nasa_train[1:5], nasa_train$hazardous)
newdata = smote$data
newdata = newdata %>% rename(hazardous=class)
newdata$hazardous = as.numeric(newdata$hazardous)

nasa_train = newdata[,1:5]
nasa_train.labels = newdata[,c("hazardous")]

nasa_train = scale(nasa_train[,1:5], center = TRUE, scale = TRUE)
nasa_test = scale(nasa_test[,1:5], center = TRUE, scale = TRUE)

library(class)
loadPkg("gmodels")
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")
knn.5 <- knn(train=nasa_train, test=nasa_test, cl=nasa_train.labels, k=7)
print(100 * sum(nasa_test.labels == knn.5)/NROW(nasa_test.labels))
confusionMatrix(knn.5, as.factor(nasa_test.labels) )
```


# hazardous = 8,000 =>80,000
non-hazardous = 80,000 => 
160,000
train =75%
test=25%
```{r,results='markup'}
#smote then split
set.seed(123)

neo_anushka = (neo %>% select(est_diameter_min, est_diameter_max, relative_velocity, absolute_magnitude, miss_distance, hazardous))
neo_anushka$hazardous[neo_anushka$hazardous == "True"] <- 1
neo_anushka$hazardous[neo_anushka$hazardous == "False"] <- 0
neo_anushka$hazardous = as.numeric(neo_anushka$hazardous)

library(smotefamily)
smote = SMOTE(neo_anushka[1:5], neo_anushka$hazardous)
newdata = smote$data
newdata = newdata %>% rename(hazardous=class)
newdata$hazardous = as.numeric(newdata$hazardous)


smp_size <- floor(0.75 * nrow(newdata))

## set the seed to make your partition reproducible
set.seed(222)
train_data_size <- sample(seq_len(nrow(newdata)), size = smp_size)


nasa_train.labels = newdata[train_data_size,c("hazardous")]
nasa_test.labels = newdata[-train_data_size,c("hazardous")]

nasa_train <- newdata[train_data_size,]
nasa_test <- newdata[-train_data_size,]

nasa_train = scale(nasa_train[,1:5], center = TRUE, scale = TRUE)
nasa_test = scale(nasa_test[,1:5], center = TRUE, scale = TRUE)

library(class)
loadPkg("gmodels")
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")
knn.5 <- knn(train=nasa_train, test=nasa_test, cl=nasa_train.labels, k=5)
print(100 * sum(nasa_test.labels == knn.5)/NROW(nasa_test.labels))
confusionMatrix(knn.5, as.factor(nasa_test.labels) )
```

Comment about why we are doing normalisation

# Standardisation
```{r, results='markup'}
#nasa_train = scale(nasa_train[,1:5], center = TRUE, scale = TRUE)
#nasa_test = scale(nasa_test[,1:5], center = TRUE, scale = TRUE)
```

# KNN
```{r, results='markup'}
library(class)
loadPkg("gmodels")
loadPkg("gmodels")
loadPkg("FNN")
loadPkg("caret")
knn.5 <- knn(train=nasa_train, test=nasa_test, cl=nasa_train.labels, k=5)
ACC.5=100 * sum(nasa_test.labels == knn.5)/NROW(nasa_test.labels)
paste0("Accuracy = ", ACC.5)
print(confusionMatrix(knn.5, as.factor(nasa_test.labels) ))

ResultDf = data.frame( k=numeric(0), Total.Accuracy= numeric(0), row.names = NULL )

for (kval in seq(1,16,2)) {
  nasa_pred <- knn(train = nasa_train, test = nasa_test, cl=nasa_train.labels, k=kval)
  cm = confusionMatrix(nasa_pred, as.factor(nasa_test.labels) ) # from caret library
  cmaccu = cm$overall['Accuracy']
  cmt = data.frame(k=kval, Total.Accuracy = cmaccu, row.names = NULL ) # initialize a row of the metrics 
  ResultDf = rbind(ResultDf, cmt)
}
xkabledply(ResultDf, "Total Accuracy Summary:")

# auc auc curve precision recall accuracy confusion matrix 
```

```{r, results='markup'}
ggplot(data=ResultDf, aes(x=k, y=Total.Accuracy,group=1)) +
  geom_line(color="#aa0022", size=1.75) +
  geom_point(color="#aa0022", size=3.5) +
  ggtitle("K value against their accuracy in KNN model") +
  labs(x="K value", y="Accuracy of K value") +
  theme(axis.title.y = element_text(size=10, family="Trebuchet MS", color="#666666")) +
  theme(axis.text = element_text(size=14, family="Trebuchet MS")) +
  theme(plot.title = element_text(size=20, family="Trebuchet MS", face="bold", hjust=0, color="#666666"))


```
From the above, we see that when k=32, we get the highest accuracy of 87.2%.
Also, noticed a higher sensitivity in the model. Why? IDK.


# SVM
```{r, results='markup'}
# install.packages("e1071")
library("e1071")
#classifier = svm(formula = nasa_train.labels ~ .,
#                 data = nasa_train,
#                 type = 'C-classification',
#                 kernel = 'linear',cost = 10)
#y_pred = predict(classifier, newdata = nasa_test)

#cm = confusionMatrix(y_pred, as.factor(nasa_test.labels) )
#cm
```

# Random Forest

```{r,results='markup'}
#nasa_model_data_randomforest = newdata
#nasa_model_data_randomforest$hazardous = as.factor(nasa_model_data_randomforest$hazardous)
## 75% of the sample size
#smp_size <- floor(0.75 * nrow(nasa_model_data_randomforest))

## set the seed to make your partition reproducible
#set.seed(123)
#train_data_size <- sample(seq_len(nrow(newdata)), size = smp_size)

#nasa_train_randomforest <- nasa_model_data_randomforest[train_data_size,]
#nasa_test_randomforest <- nasa_model_data_randomforest[-train_data_size,]


#library(randomForest)
#library("pROC") 
#classifier <- randomForest( formula = hazardous~., data=nasa_train_randomforest)
#print(classifier)

#pred_1 = predict(classifier, nasa_test_randomforest, type="prob")
#paste0("Accuracy = ",mean(nasa_test_randomforest$hazardous == pred_1))

#nasa_test_randomforest$prob = as.numeric(unlist(as.data.frame(pred_1)[2]))
#nasa_test_randomforest$hazardous = as.numeric(as.character(nasa_test_randomforest$hazardous))
#nasa_test_randomforest$prob = round(nasa_test_randomforest$prob)
#h <- roc(hazardous~prob, data=nasa_test_randomforest)
#print(h)
#plot(h,main="ROC Curve for Random Forest",col=2,lwd=2)


#varImpPlot(classifier)

```
Classifier estimate of error = 9.7%. Which means that accuracy is 90.3%.
Area under curve is 0.908. Very good fit model.

# KNN model Evaluation
```{r, results='markup'}

# auc auc curve precision recall accuracy confusion matrix 
# with k=15

knn.11 <- knn(train=nasa_train, test=nasa_test, cl=nasa_train.labels, k=9, prob=TRUE)
print(confusionMatrix(knn.11, as.factor(nasa_test.labels), mode = "everything"))

library(pROC)

print(roc(nasa_test.labels, attributes(knn.11)$prob))

plot(roc(nasa_test.labels, attributes(knn.11)$prob),
     print.thres = T,
     print.auc=T)


```

# Limitations

The `neo.csv` data set posed limitations in the variables, description and dictionary. Since the dataset was obtained from a web-based environment, kaggle, we had insufficient variables, a poor description of the dataset and no data dictionary provided. In terms of the variables provided, it would have been ideal to have one regarding the trajectory towards, or away, from earth, as well as other potentially hazardous, or not hazardous, variables. Nevertheless, we were restricted to just using the three variables that were quantifiable in order to characterize the potential of it being hazardous. In retrospect, just using these three variables might have been an over-simplification in our determination of a hazard. On the other hand, the description of the dataset is very limited given the constraint of using Kaggle. It would have been better if the dataset was obtained straight from a NASA website or API, however this was not possible. It would have been a huge perk to know how these variables are being used by NASA professionals, what characterizes an instance to be recorded multiple times, and why they initially attributed the boolean value for Hazardous. Finally, when it came to providing a data dictionary, the kaggle website did not have one. Thus, we had to do our own research as to what these variables meant, and what they were describing. Therefore, with insufficient variables, a poor description and no data dictionary it was difficult to infer, or fully understand, the root of a hazardous or not hazardous asteroid to fully answer our question.


# References:

- Kaggle Dataset (Kaggle):
Vani, S. (2022, June 17). NASA - Nearest Earth objects. Kaggle. Retrieved November 2, 2022, from https://www.kaggle.com/datasets/sameepvani/nasa-nearest-earth-objects 
- Center for Near Earth Objects Studies (CNEOS):
NASA. (n.d.). Neo basics. NASA. Retrieved November 2, 2022, from https://cneos.jpl.nasa.gov/about/neo_groups.html 
- NASA (NASA):
Bardan, R. (2022, October 11). NASA confirms Dart Mission Impact Changed Asteroid's motion in space. NASA. Retrieved November 2, 2022, from https://www.nasa.gov/press-release/nasa-confirms-dart-mission-impact-changed-asteroid-s-motion-in-space 
- Araujo, R. A. N., & Winter, O. C. (2014). Near-Earth asteroid binaries in close encounters with the Earth. Astronomy & Astrophysics, 566, A23.
- Peter O. K. Krehl (2008). History of Shock Waves, Explosions and Impact: A Chronological and Biographical Reference. Springer Science & Business Media. p. 404. ISBN 978-3-540-30421-0.
- Tonry, J. L. (2010). An early warning system for asteroid impact. Publications of the Astronomical Society of the Pacific, 123(899), 58.






